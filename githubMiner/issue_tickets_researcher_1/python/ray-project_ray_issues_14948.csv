,target,doc
0,1,Object spilling to S3 crashes
1,1,"<!--Please include [tune], [rllib], [autoscaler] etc. in the issue title if relevant-->"
2,1,
3,1,### What is the problem?
4,,
5,1,"*Ray version and other system information (Python version, TensorFlow version, OS):*"
6,,
7,1,- Ray: 2.0.0 nightly
8,1,- Python 3.8.5
9,1,- OS: Ubuntu 18.04
10,1,- AWS EC2 instance
11,,
12,1,### Reproduction (REQUIRED)
13,1,"Please provide a short code snippet (less than 50 lines if possible) that can be copy-pasted to reproduce the issue. The snippet should have **no external library dependencies** (i.e., use fake or mock data / environments):"
14,,
15,1,Repro script:
16,,
17,0,```
18,0,import numpy as np
19,0,import ray
20,0,
21,0,MAPPER_PART_SIZE = 2 * 1024 * 1024 * 1024
22,0,M = 4
23,0,R = 4
24,0,
25,0,
26,0,"@ray.remote(resources={""worker"": 1})"
27,0,def mapper(mapper_id):
28,0,"    print(""Mapper"", mapper_id)"
29,0,    part_size = int(MAPPER_PART_SIZE / R)
30,0,"    ret = [b""0"" * part_size for _ in range(R)]"
31,0,    return ret
32,0,
33,0,
34,0,"@ray.remote(resources={""worker"": 1})"
35,0,"def reducer(reducer_id, *chunks):"
36,0,"    print(""Reducer"", reducer_id)"
37,0,    print([len(c) for c in chunks])
38,0,    return 0
39,0,
40,0,
41,0,"ray.init(address=""auto"")"
42,0,
43,0,"mapper_results = np.empty((M, R), dtype=object)"
44,0,
45,0,for m in range(M):
46,0,"    mapper_results[m, :] = mapper.options(num_returns=R).remote(m)"
47,0,
48,0,reducer_results = []
49,0,for r in range(R):
50,0,"    chunks = mapper_results[:, r].tolist()"
51,0,"    ret = reducer.remote(r, *chunks)"
52,0,    reducer_results.append(ret)
53,0,
54,0,ray.get(reducer_results)
55,0,"print(""OK"")"
56,0,```
57,,
58,1,"Launch Ray with: `ray stop && ray start --head --system-config='{""automatic_object_spilling_enabled"":true,""max_io_workers"":4,""min_spilling_size"":104857600,""object_spilling_config"":""{\""type\"":\""smart_open\"",\""params\"":{\""uri\"":\""s3://raysort-debug/spill\""}}""}' --resources='{""worker"":1}' --object-store-memory 6400000000`"
59,,
60,1,Run log:
61,,
62,0,```
63,0,"2021-03-25 16:18:05,386 INFO worker.py:654 -- Connecting to existing Ray cluster at address: 172.31.61.153:6379"
64,0,(pid=23362) Mapper 0
65,0,(pid=23362) Mapper 1
66,0,(pid=23362) Mapper 2
67,0,(pid=23362) Mapper 3
68,0,(pid=23362) Reducer 0
69,0,"(pid=23362) [536870912, 536870912, 536870912, 536870912]"
70,0,"(raylet) [2021-03-25 16:33:25,392 C 22852 22852] local_object_manager.cc:316:  Check failed: objects_pending_restore_.emplace(object_id).second Object dedupe wasn't done properly. Please report if you see this issue."
71,0,"(raylet) [2021-03-25 16:33:25,392 E 22852 22852] logging.cc:415: *** Aborted at 1616715205 (unix time) try ""date -d @1616715205"" if you are using GNU date ***"
72,0,"(raylet) [2021-03-25 16:33:25,393 E 22852 22852] logging.cc:415: PC: @                0x0 (unknown)"
73,0,"(raylet) [2021-03-25 16:33:25,393 E 22852 22852] logging.cc:415: *** SIGABRT (@0x3e800005944) received by PID 22852 (TID 0x7ff72be9d800) from PID 22852; stack trace: ***"
74,0,"(raylet) [2021-03-25 16:33:25,393 E 22852 22852] logging.cc:415:     @     0x5623a84145df google::(anonymous namespace)::FailureSignalHandler()"
75,0,"(raylet) [2021-03-25 16:33:25,393 E 22852 22852] logging.cc:415:     @     0x7ff72ba7b980 (unknown)"
76,0,"(raylet) [2021-03-25 16:33:25,393 E 22852 22852] logging.cc:415:     @     0x7ff72ab24fb7 gsignal"
77,0,"(raylet) [2021-03-25 16:33:25,393 E 22852 22852] logging.cc:415:     @     0x7ff72ab26921 abort"
78,0,"(raylet) [2021-03-25 16:33:25,394 E 22852 22852] logging.cc:415:     @     0x5623a7fca3a6 _ZN3ray6RayLogD2Ev.cold"
79,0,"(raylet) [2021-03-25 16:33:25,394 E 22852 22852] logging.cc:415:     @     0x5623a806d673 _ZZN3ray6raylet18LocalObjectManager25AsyncRestoreSpilledObjectERKNS_8ObjectIDERKSsSt8functionIFvRKNS_6StatusEEEENKUlSt10shared_ptrINS0_15WorkerInterfaceEEE_clESF_"
80,0,"(raylet) [2021-03-25 16:33:25,394 E 22852 22852] logging.cc:415:     @     0x5623a806d9b5 _ZNSt17_Function_handlerIFvSt10shared_ptrIN3ray6raylet15WorkerInterfaceEEEZNS2_18LocalObjectManager25AsyncRestoreSpilledObjectERKNS1_8ObjectIDERKSsSt8functionIFvRKNS1_6StatusEEEEUlS4_E_E9_M_invokeERKSt9_Any_dataOS4_"
81,0,"(raylet) [2021-03-25 16:33:25,394 E 22852 22852] logging.cc:415:     @     0x5623a804b3bd ray::raylet::WorkerPool::PushIOWorkerInternal()"
82,0,"(raylet) [2021-03-25 16:33:25,394 E 22852 22852] logging.cc:415:     @     0x5623a804b5a8 ray::raylet::WorkerPool::PushRestoreWorker()"
83,0,"(raylet) [2021-03-25 16:33:25,395 E 22852 22852] logging.cc:415:     @     0x5623a80698fb _ZNSt17_Function_handlerIFvRKN3ray6StatusERKNS0_3rpc26RestoreSpilledObjectsReplyEEZZNS0_6raylet18LocalObjectManager25AsyncRestoreSpilledObjectERKNS0_8ObjectIDERKSsSt8functionIFvS3_EEENKUlSt10shared_ptrINS9_15WorkerInterfaceEEE_clESL_EUlS3_S7_E_E9_M_invokeERKSt9_Any_dataS3_S7_"
84,0,"(raylet) [2021-03-25 16:33:25,395 E 22852 22852] logging.cc:415:     @     0x5623a807374f ray::rpc::ClientCallImpl<>::OnReplyReceived()"
85,0,"(raylet) [2021-03-25 16:33:25,395 E 22852 22852] logging.cc:415:     @     0x5623a8084c82 _ZN5boost4asio6detail18completion_handlerIZN3ray3rpc17ClientCallManager29PollEventsFromCompletionQueueEiEUlvE_E11do_completeEPvPNS1_19scheduler_operationERKNS_6system10error_codeEm"
86,0,"(raylet) [2021-03-25 16:33:25,396 E 22852 22852] logging.cc:415:     @     0x5623a8781aa1 boost::asio::detail::scheduler::do_run_one()"
87,0,"(raylet) [2021-03-25 16:33:25,398 E 22852 22852] logging.cc:415:     @     0x5623a8783149 boost::asio::detail::scheduler::run()"
88,0,"(raylet) [2021-03-25 16:33:25,398 E 22852 22852] logging.cc:415:     @     0x5623a8785637 boost::asio::io_context::run()"
89,0,"(raylet) [2021-03-25 16:33:25,398 E 22852 22852] logging.cc:415:     @     0x5623a7fe6182 main"
90,0,"(raylet) [2021-03-25 16:33:25,398 E 22852 22852] logging.cc:415:     @     0x7ff72ab07bf7 __libc_start_main"
91,0,"(raylet) [2021-03-25 16:33:25,400 E 22852 22852] logging.cc:415:     @     0x5623a7ffab55 (unknown)"
92,0,[1]    23199 abort (core dumped)  python -u repro.py
93,0,```
94,,
95,1,"This consistently happens with spilling to S3. When spilling to local disk (`/tmp/spill`), this config works fine; but heavier configs (e.g. 4GB partition size) sometimes also yield this error."
96,,
97,1,"If the code snippet cannot be run by itself, the issue will be closed with ""needs-repro-script""."
98,,
99,1,- [x] I have verified my script runs in a clean environment and reproduces the issue.
100,1,- [x] I have verified the issue also occurs with the [latest wheels](https://docs.ray.io/en/master/installation.html).

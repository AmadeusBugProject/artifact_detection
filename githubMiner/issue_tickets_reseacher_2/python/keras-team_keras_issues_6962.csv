,target,doc
0,1,How do you iterate or enumerate through a Keras model saved in HDF5?
1,1,For the following code to load the Keras HDF5 model file from the examples/imdb_cnn.py:
2,0,
3,0,```
4,0,#!/usr/bin/env python
5,0,
6,0,import h5py
7,0,import os
8,0,
9,0,filename = 'imdb_cnn.h5'
10,0,"f = h5py.File(filename, 'r')"
11,0,for item in f.attrs.keys():
12,0,"    print item + "":"", f.attrs[item] + '\n'"
13,0,```
14,1,I get the following output:
15,0,
16,0,```
17,0,keras_version: 2.0.4
18,0,
19,0,backend: tensorflow
20,0,
21,0,"model_config: {""class_name"": ""Sequential"", ""config"": [{""class_name"": ""Embedding"", ""config"": {""embeddings_initializer"": {""class_name"": ""RandomUniform"", ""config"": {""maxval"": 0.05, ""seed"": null, ""minval"": -0.05}}, ""name"": ""embedding_1"", ""dtype"": ""int32"", ""output_dim"": 50, ""trainable"": true, ""embeddings_regularizer"": null, ""input_dim"": 5000, ""mask_zero"": false, ""embeddings_constraint"": null, ""batch_input_shape"": [null, 400], ""activity_regularizer"": null, ""input_length"": 400}}, {""class_name"": ""Dropout"", ""config"": {""rate"": 0.2, ""trainable"": true, ""name"": ""dropout_1""}}, {""class_name"": ""Conv1D"", ""config"": {""kernel_constraint"": null, ""kernel_initializer"": {""class_name"": ""VarianceScaling"", ""config"": {""distribution"": ""uniform"", ""scale"": 1.0, ""seed"": null, ""mode"": ""fan_avg""}}, ""name"": ""conv1d_1"", ""bias_regularizer"": null, ""bias_constraint"": null, ""activation"": ""relu"", ""trainable"": true, ""padding"": ""valid"", ""strides"": [1], ""dilation_rate"": [1], ""kernel_regularizer"": null, ""filters"": 250, ""bias_initializer"": {""class_name"": ""Zeros"", ""config"": {}}, ""use_bias"": true, ""activity_regularizer"": null, ""kernel_size"": [3]}}, {""class_name"": ""GlobalMaxPooling1D"", ""config"": {""trainable"": true, ""name"": ""global_max_pooling1d_1""}}, {""class_name"": ""Dense"", ""config"": {""kernel_initializer"": {""class_name"": ""VarianceScaling"", ""config"": {""distribution"": ""uniform"", ""scale"": 1.0, ""seed"": null, ""mode"": ""fan_avg""}}, ""name"": ""dense_1"", ""kernel_constraint"": null, ""bias_regularizer"": null, ""bias_constraint"": null, ""activation"": ""linear"", ""trainable"": true, ""kernel_regularizer"": null, ""bias_initializer"": {""class_name"": ""Zeros"", ""config"": {}}, ""units"": 250, ""use_bias"": true, ""activity_regularizer"": null}}, {""class_name"": ""Dropout"", ""config"": {""rate"": 0.2, ""trainable"": true, ""name"": ""dropout_2""}}, {""class_name"": ""Activation"", ""config"": {""activation"": ""relu"", ""trainable"": true, ""name"": ""activation_1""}}, {""class_name"": ""Dense"", ""config"": {""kernel_initializer"": {""class_name"": ""VarianceScaling"", ""config"": {""distribution"": ""uniform"", ""scale"": 1.0, ""seed"": null, ""mode"": ""fan_avg""}}, ""name"": ""dense_2"", ""kernel_constraint"": null, ""bias_regularizer"": null, ""bias_constraint"": null, ""activation"": ""linear"", ""trainable"": true, ""kernel_regularizer"": null, ""bias_initializer"": {""class_name"": ""Zeros"", ""config"": {}}, ""units"": 1, ""use_bias"": true, ""activity_regularizer"": null}}, {""class_name"": ""Activation"", ""config"": {""activation"": ""sigmoid"", ""trainable"": true, ""name"": ""activation_2""}}]}"
22,0,
23,0,"training_config: {""metrics"": [""accuracy""], ""loss"": ""binary_crossentropy"", ""optimizer_config"": {""class_name"": ""Adam"", ""config"": {""beta_1"": 0.8999999761581421, ""epsilon"": 1e-08, ""beta_2"": 0.9990000128746033, ""lr"": 0.0010000000474974513, ""decay"": 0.0}}, ""loss_weights"": null, ""sample_weight_mode"": null}"
24,0,```
25,0,
26,1,How do I iterate or enumerate through the saved HDF5 file of Keras format and extract all the weight matricies and all the layer and network configuration?  I already looked at the engine/topology.py and the keras/models.py for how the save_model() function works but the code doesn't lead me to know a good way to make the saved file readable and visualizable?
27,0,
28,1,"I am thinking about contributing a hdf5 file visualizer to keras in the future but first, I need to know how to interpret the file.  Could someone help?"
